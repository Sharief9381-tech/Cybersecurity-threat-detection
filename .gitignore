import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

def preprocess_data(data):
    data = data.drop(['timestamp', 'source_ip'], axis=1)
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(data[['data_size']])
    return scaled_data

def train_anomaly_detection_model(data):
    model = IsolationForest(contamination=0.05)
    model.fit(data)
    return model

def detect_anomalies(model, data):
    anomalies = model.predict(data)
    return anomalies

if __name__ == "__main__":
    data = pd.read_csv('data/sample_logs.csv')
    preprocessed_data = preprocess_data(data)
    model = train_anomaly_detection_model(preprocessed_data)
    anomalies = detect_anomalies(model, preprocessed_data)
    anomaly_indices = [i for i, value in enumerate(anomalies) if value == -1]
    print(f"Anomalous data indices: {anomaly_indices}")
